{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG, ou Retrieval-Augmented Generation (Geração Aumentada por Recuperação), é uma técnica híbrida que combina modelos de recuperação de informações com modelos de geração de texto (geralmente LLMs, como GPT ou BERT). O objetivo do RAG é melhorar a capacidade de um modelo de linguagem em fornecer respostas mais precisas e informadas, especialmente em cenários onde o modelo pode não ter todos os dados contextuais na memória ou no treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o RAG funciona:\n",
    "1. Recuperação de Informação (Retrieval): \n",
    "\n",
    "* Em vez de confiar exclusivamente no conhecimento armazenado no modelo de linguagem, o sistema RAG inclui uma etapa de recuperação de informações. O modelo de recuperação (como um mecanismo de busca ou uma loja de vetores) busca informações relevantes em uma base de dados externa, como documentos, artigos ou outros textos, que são relacionados à consulta do usuário. \n",
    "* Isso é útil quando o modelo de linguagem não tem conhecimento completo ou atualizado sobre o assunto, permitindo que ele acesse novas informações ou dados que não estavam disponíveis durante o treinamento.\n",
    "\n",
    "2. Geração de Resposta (Generation):\n",
    "\n",
    "* Após a recuperação das informações relevantes, essas informações são passadas para um modelo de geração de texto. O modelo de linguagem (como GPT ou BERT) então processa a consulta original do usuário e as informações recuperadas para gerar uma resposta mais precisa e detalhada.\n",
    "* O modelo não apenas repete o que foi recuperado, mas integra esses dados com sua própria capacidade de gerar linguagem, criando uma resposta fluida, coerente e contextual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot com dados próprios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante: Executar o pop de pysqlite3 apenas se estiver em MAC OS ou Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a codificar, primeiro importando as blibliotecas para criar o CHAT.Vamos usar um modelo opensource Llama-3.2-3B-Instruct, para ter acesso a ele, precisa ter uma conta no Hugging Face e solicitar acesso ao modelo em: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimmy/Projects/dimmy/chat_langchain/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/dimmy/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "\n",
    "model = 'meta-llama/Llama-3.2-3B-Instruct' #Vamos usar um modelo opensource.\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id=model) # na primeira execução, o modelo será baixado\n",
    "chat = ChatHuggingFace(llm=llm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando estrutura de Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Chroma de langchain_community.vectorstores.chroma: O Chroma é uma implementação de uma loja de vetores (vector store), que é usada para armazenar e recuperar representações vetoriais de textos ou documentos. Essas representações são úteis em tarefas de busca semântica e recuperação de informações, permitindo consultas mais eficientes e relevantes. O Chroma é uma opção popular de loja de vetores na comunidade de LangChain, usada em combinação com embeddings para indexar e buscar dados de texto de forma eficaz.\n",
    "PyPDFLoader de langchain_community.document_loaders.pdf:\n",
    "\n",
    "2. O PyPDFLoader é um carregador de documentos específico para arquivos PDF. Ele utiliza a biblioteca PyPDF para ler e carregar o conteúdo dos PDFs em um formato que possa ser usado dentro da aplicação LangChain, transformando o texto em algo que possa ser processado posteriormente, como para extração de informações ou divisão do texto em segmentos menores.\n",
    "RecursiveCharacterTextSplitter de langchain_text_splitters:\n",
    "\n",
    "3. O RecursiveCharacterTextSplitter é uma ferramenta que divide um texto em partes menores. Essa técnica é útil para garantir que os segmentos de texto estejam dentro dos limites de tokens que podem ser processados por um LLM. O algoritmo recursivo tenta dividir o texto em quebras naturais, como parágrafos ou sentenças, para manter o contexto dentro das partes, mesmo com grandes documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf', 'TranstornoEspectroAutista.pdf']\n"
     ]
    }
   ],
   "source": [
    "# listando arquivos na pasta files\n",
    "import os\n",
    "dir = 'files'\n",
    "files = os.listdir(dir)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando arquivos em pages usando PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "for path in files:\n",
    "    loader = PyPDFLoader(os.path.join(dir, path))\n",
    "    pages.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517\n"
     ]
    }
   ],
   "source": [
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As páginas podem conter conteúdo demais, ou seja, com janelas de contexto que os modelos de LLM não conseguem armazenar. Para tanto precisamos quebrar esses textos em elementos semanticamente válidos. Para isso vamos usar o RecursiveCharacterTexetSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de páginas:  1527\n"
     ]
    }
   ],
   "source": [
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, #tamanho do chunk (pedaço) do texto\n",
    "    chunk_overlap=100, #overplap entre os chunks, ou seja, quantos caracteres de um chunk são repetidos no próximo (10%)\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "#Executando o split dos documentos\n",
    "documents = recur_split.split_documents(pages)\n",
    "print(\"Quantidade de páginas: \", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Autismo: compreensão e práticas baseadas em evidências\\nAUTISMO:\\nCOMPREENSÃO E PRÁTICAS\\nBASEADAS EM EVIDÊNCIAS', metadata={'source': 'files/AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf', 'page': 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modificando os metadados dos documentos\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    doc.metadata['source'] = doc.metadata['source'].replace('files/', '')\n",
    "    #Aqui podemos colocar algo como keywords, autores, etc..\n",
    "    doc.metadata['keywords'] = \"Autismo, Educação, Inclusão\"\n",
    "    doc.metadata['doc_id'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois dos dados seperadados vamos armazenar em um vector_store. Um vector store é uma estrutura de armazenamento que guarda representações vetoriais (embeddings) de dados, geralmente texto, para facilitar a recuperação de informações ou a busca semântica. É uma peça fundamental em sistemas de inteligência artificial que trabalham com modelos de linguagem natural (LLMs), principalmente em tarefas de busca, recomendação e análise de similaridade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como precisamos de um embedding de cada texto, precisamos de uma forma de transformar o texto em embedding. Iremos usar também de código aberto. Solicite acesso a ele em: https://huggingface.co/meta-llama/Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model = 'thuan9889/llama_embedding_model_v1'\n",
    "embedding_model = HuggingFaceBgeEmbeddings(model_name = model) # na primeira execução, o modelo será baixado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_vector_store = 'vector_stores/chat_retrieval_db_omni'\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=dir_vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando cadeias de execuções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando vector store (caso tenha sido salvo):\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=dir_vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para deixar o exemplo mais completo, usaremos um prompt_template a fim de personalizar nosso agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Utilize o contexto fornecido para responder à pergunta com empatia e precisão, considerando que o tema é autismo.\n",
    "    Se você não souber a resposta com certeza, informe que não sabe e não tente especular.\n",
    "    Mantenha a resposta breve e clara, em no máximo três frases, e sempre priorize um tom acolhedor e respeitoso.\n",
    "\n",
    "    Contexto: {context}\n",
    "\n",
    "    Pergunta: {question}\n",
    "\n",
    "    Resposta:\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'), # max marginal relevance\n",
    "                                                        # que é um algoritmo de diversidade de documentos\n",
    "    chain_type_kwargs={'prompt': chain_prompt}, #adicionando o template\n",
    "    return_source_documents=True #quais documentos foram usados para responder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'autismo só afeta crianças?'\n",
    "response = chat_chain.invoke({'query': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Não, o autismo não só afeta crianças. Embora seja mais comum em crianças, o autismo pode afetar pessoas de todas as idades, desde a infância até a velhice.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 59, 'source': 'files/AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['source_documents'][0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Como o autismo se manifesta?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Como o autismo se manifesta?\",\n",
      "  \"context\": \"Autismo: compreensão e práticas baseadas em evidências\\n\\nAutismo: compreensão e práticas baseadas em evidências\\n\\nAutismo: compreensão e práticas baseadas em evidências\\n\\nAutismo: compreensão e práticas baseadas em evidências\\nAUTISMO: COMPREENSÃO E PRÁTICAS BASEADAS EM EVIDÊNCIAS\\nEsta obra não é vendida. Ela faz parte de um projeto educativo, sem fins\\nlucrativos. Todos os direitos reservados.\\ncontato: caprichanainclusao@gmail.com\\nAutores: Paulo Liberalesso\\nLucelmo Lacerda\\nElyse Matos\\nMarlla MendesOrganização:\\nMaria Alice Mendes Revisão:\\nProjeto gráfico, capa e diagramação:\\nSupervisão:Marcos Venicius Valentin\\nElyse Matos\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatHuggingFace] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Utilize o contexto fornecido para responder à pergunta com empatia e precisão, considerando que o tema é autismo.\\n    Se você não souber a resposta com certeza, informe que não sabe e não tente especular.\\n    Não lamente quando não souber uma resposta completa.\\n    Mantenha a resposta breve e clara, em no máximo três frases, e sempre priorize um tom acolhedor e respeitoso.\\n\\n    Contexto: Autismo: compreensão e práticas baseadas em evidências\\n\\nAutismo: compreensão e práticas baseadas em evidências\\n\\nAutismo: compreensão e práticas baseadas em evidências\\n\\nAutismo: compreensão e práticas baseadas em evidências\\nAUTISMO: COMPREENSÃO E PRÁTICAS BASEADAS EM EVIDÊNCIAS\\nEsta obra não é vendida. Ela faz parte de um projeto educativo, sem fins\\nlucrativos. Todos os direitos reservados.\\ncontato: caprichanainclusao@gmail.com\\nAutores: Paulo Liberalesso\\nLucelmo Lacerda\\nElyse Matos\\nMarlla MendesOrganização:\\nMaria Alice Mendes Revisão:\\nProjeto gráfico, capa e diagramação:\\nSupervisão:Marcos Venicius Valentin\\nElyse Matos\\n\\n    Pergunta: Como o autismo se manifesta?\\n\\n    Resposta:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatHuggingFace] [1.33s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Lamento não ter informações sobre como o autismo se manifesta, pois não tenho conhecimento específico sobre o tema. Se você estiver procurando informações sobre os sintomas e características do autismo, recomendo consultar uma fonte confiável ou especialista em saúde mental. Estou aqui para ajudar com qualquer outra coisa.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Lamento não ter informações sobre como o autismo se manifesta, pois não tenho conhecimento específico sobre o tema. Se você estiver procurando informações sobre os sintomas e características do autismo, recomendo consultar uma fonte confiável ou especialista em saúde mental. Estou aqui para ajudar com qualquer outra coisa.\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-d38d22d6-ec4a-4d2c-9e03-cee3fae62b86-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Lamento não ter informações sobre como o autismo se manifesta, pois não tenho conhecimento específico sobre o tema. Se você estiver procurando informações sobre os sintomas e características do autismo, recomendo consultar uma fonte confiável ou especialista em saúde mental. Estou aqui para ajudar com qualquer outra coisa.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.33s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Lamento não ter informações sobre como o autismo se manifesta, pois não tenho conhecimento específico sobre o tema. Se você estiver procurando informações sobre os sintomas e características do autismo, recomendo consultar uma fonte confiável ou especialista em saúde mental. Estou aqui para ajudar com qualquer outra coisa.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [1.34s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "question = 'Como o autismo se manifesta?'\n",
    "response = chat_chain.invoke({'query': question})\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Como o autismo se manifesta?',\n",
       " 'result': 'Lamento não ter informações sobre como o autismo se manifesta, pois não tenho conhecimento específico sobre o tema. Se você estiver procurando informações sobre os sintomas e características do autismo, recomendo consultar uma fonte confiável ou especialista em saúde mental. Estou aqui para ajudar com qualquer outra coisa.',\n",
       " 'source_documents': [Document(page_content='Autismo: compreensão e práticas baseadas em evidências', metadata={'page': 11, 'source': 'files/AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf'}),\n",
       "  Document(page_content='Autismo: compreensão e práticas baseadas em evidências', metadata={'page': 13, 'source': 'files/AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf'}),\n",
       "  Document(page_content='Autismo: compreensão e práticas baseadas em evidências', metadata={'page': 3, 'source': 'files/AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf'}),\n",
       "  Document(page_content='Autismo: compreensão e práticas baseadas em evidências\\nAUTISMO: COMPREENSÃO E PRÁTICAS BASEADAS EM EVIDÊNCIAS\\nEsta obra não é vendida. Ela faz parte de um projeto educativo, sem fins\\nlucrativos. Todos os direitos reservados.\\ncontato: caprichanainclusao@gmail.com\\nAutores: Paulo Liberalesso\\nLucelmo Lacerda\\nElyse Matos\\nMarlla MendesOrganização:\\nMaria Alice Mendes Revisão:\\nProjeto gráfico, capa e diagramação:\\nSupervisão:Marcos Venicius Valentin\\nElyse Matos', metadata={'page': 5, 'source': 'files/AUTISMO - PRATICAS BASEADAS EM EVIDENCIAS.pdf'})]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
